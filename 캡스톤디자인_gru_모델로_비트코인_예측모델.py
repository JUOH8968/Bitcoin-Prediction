# -*- coding: utf-8 -*-
"""캡스톤디자인_GRU 모델로 비트코인 예측모델.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WbnYCLt5l418nlOliMAWjsPEJlscKGgy

#############
### 0. 데이터 증가(2012.05.20~ 2025.05.20)
### 1. 트럼프 관세(비트코인영향)
### 2. dropout(정규화), early stoping  -> 과적합방지
### 3. learning late ==> 하이퍼파라미터
### 4. 함수로 묶기

# 1. GRU 모델을 사용하여 비트코인 예측하는 프로그램

##  1- 1. 데이터 불러오기 ( 2018년~ 2022년 데이터 학습 한후 2023년 예측)
"""

!pip install finance-datareader # FinanceDataReader에서 데이터를 불러오기 위해 FinanceDataReader를 설치하는 과정

#### 나스닥 지수 + 환율데이터 + 코인데이터 를 활용하여 종가 예측하기
#### 추가로  뉴스 및 소셜 미디어 감성 분석을 하여 긍정인 뉴스는 1로, 부정인 뉴스는 0으로 라벨링 하여 진행하기
############# 이코드 사용하기
import pandas as pd
import numpy as np
import FinanceDataReader as fdr
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, GRU,Dropout
from sklearn.metrics import r2_score
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

# 데이터 불러오기
start_date = "2018-01-01" # "2018-01-01"
end_date = "2025-08-20"  #23.03.01  ,   "2022-12-31"
ticker = "BTC/KRW"  # 한국거래소에서 비트코인을 가격 데이터 가져오기
df = pd.DataFrame(fdr.DataReader(ticker, start_date, end_date))

## 비트코인 데이터
df

"""## 1-2. 데이터 전처리"""

# 6개의 열 학습
# 데이터 전처리
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(df.iloc[:,3:4]) # minmaxScaler는 스케일을 조정하는 정규화 함수로, 모든 데이터가 0과 1사이의 값을 갖도록 해주는 함수이다
                          # 따라서 최댓값은 1로, 최솟값은 0으로 데이터의 범위를 조정해준다. 객체생성함

scaled_data.shape # (2, 6)

# train, test 데이터 생성

train_size = int(len(scaled_data) * 0.7)   ## 전체 데이터셋 중 70%를 학습 데이터셋으로, 20%를 테스트 데이터셋(검증용) 으로 사용하기 위해서 0.8을 곱했다
                                          # 모델 학습 시 과적합을 방지하고 일반화 성능을 높이기 위해 사용된다
train_data = scaled_data[:train_size] # 1789
test_data = scaled_data[train_size:] # 768

def create_dataset(data, look_back): #look_back은 몇 개의 과거 데이터를 사용할 것인지를 표현하는 것이다(기본값이 60이다)
    x, y = [], []        #  for문에서 얻은 모든 입력 데이터(x)와 출력 데이터(y)를 리스트에 추가한다
    for i in range(len(data)-look_back):  # train : 1759까지 , test: 738까지
        x.append(data[i:(i+look_back), :])   # i부터 (i+look_back)까지의 데이터를 하나의 입력 데이터 x 로 표현한다, 종가와 저가사용
        y.append([data[i+look_back, :]])       # i+look_back의 데이터를 출력 데이터 y 로 표현한다.
    return np.array(x), np.array(y)         # 리스트를 numpy 배열로 변환하여 반환

# create_dataset()는 시계열 데이터를 RNN 모델에 입력으로 사용하기 위해 입력 데이터와 출력 데이터로 분리하는 함수이다.

look_back = 60
x_train, y_train = create_dataset(train_data, look_back)
x_test, y_test = create_dataset(test_data, look_back)

x_train.shape, y_train.shape, x_test.shape, y_test.shape
# x_train.shpae : (샘플수, look_back, 특성개수)
# y_train.shape : (샘플수, 예측 한날의 정답, 특성개수)
# x_test.shape :  (샘플수 , look_back, 특성개수)
# y_test.shape :  (샘플수, 예측 한날의 정답, 특성개수)

"""## 1-3. GRU 모델 생성"""

# 모델 생성
es = EarlyStopping(monitor= 'val_loss', mode='min', verbose=1, patience=5)
  # 검증손실이 5번연속 줄지않으면 학습중단 , verbose=1 :자세히출력, 0;출력x , 2:함축적인정보만 출력

mc= ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', verbose=1,save_best_only=True)
  # 검증손실이 가장 작을때의 모델만 저장
model = Sequential()   # 모델의 객체생성
model.add(GRU(150, input_shape=(look_back, 1)))   #  50=레이어의 출력 차원, input_shape=입력 데이터의 형태를 정의를 의미한다.
                                                  # lock_back=이전 데이터의 갯수만큼 비트코인 가격을 입력으로 받아들이고, 각각의 데이터가 1차원인 것을 의미합니다.
model.add(Dropout(0.2))
model.add(Dense(1))   # Dense 는 완전 연결 레이어(층)를 의미한다. 1은 출력의 차원을 의미

model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse', 'mae'] )  # compile() 함수를 이용하여 모델을 컴파일합니다
                                                             # loss는 손실 함수를 의미한다.
                                                             # mean_squared_error(MSE) 는 전체 에러를 표현하기 위해서 사용하는 식이고 오차의 제곱에 대해 평균을 취한 것이다.(수치가 작을 수록 원본과의 오차가 적은 것이다)
                                                             # optimizer는  최적화 알고리즘을 정의하는 부분이다. adam(아담) 은 모멘텀+ AdaGrad(아다그라드) 을 합친 것이다

# 완전 연결 레이어 : 한 레이어의 모든 뉴런이 그 다음 레이어의 모든 뉴런과 연결된 상태이다.
# 모멘텀 : 기울기 방향으로 힘을 받아 물체가 가속된다는 물리법칙을 적용한것이다.
# AdaGrad : 학습을 진행하면서 학습률을 점차 줄여가는 방법이다.

"""## 1-4. GRU 모델 학습"""

# 모델 학습
model.fit(x_train, y_train, epochs=100, validation_data=(x_test, y_test),callbacks=[es,mc], batch_size=32, validation_split=0.1, verbose=2)

# x_train : 학습데이터의 입력값   , y_train : 학습데이터의 출력값이다.

# 에포크 : 훈련 데이터셋에 포함된 모든 데이터들이 한 번씩 모델을 통과한 횟수 또는 전체 학습 데이터셋에 대한 반복 횟수이다
# 에포크가 높을수록 더 많은 반복 학습을 수행하게 되므로 모델이 더 많은 학습을 하게 되어 일반적으로 더 좋은 성능을 낼 수 있습니다

# batch_size(배치크기) : 학습을 수행할 때, 몇 개의 데이터를 한 번에 처리할지를 지정한다, 일반적으로 32,64, 128 숫자를 사용한다

# verbose : 학습 과정 중 출력되는 문구를 설정합니다. 0일 경우 출력하지 않으며, 1일 경우 학습 진행 상황을 출력하고, 2일 경우 학습 결과만 출력한다

"""## 1-5. 예측"""

# 예측
train_predict = model.predict(x_train)  # (1759, 6)
test_predict = model.predict(x_test) #  (738, 6)

# model.predict(x_train) 은 학습된 모델을 이용하여 train 데이터에 대한 예측값을 계산한다
# mode.predict(x_test) 은 학습된 모델을 이용하여 test 데이터에 대한 예측값을 계산한다.

train_predict = scaler.inverse_transform(train_predict)
y_train = scaler.inverse_transform(y_train.reshape(-1,1))
test_predict = scaler.inverse_transform(test_predict)
y_test = scaler.inverse_transform(y_test.reshape(-1,1))

train_predict.shape, y_train.shape, test_predict.shape, y_test.shape

"""## 1-6. 모델 시각화
### https://wikidocs.net/92088
"""

import datetime
import matplotlib.pyplot as plt
import matplotlib.ticker as mticker

# train 데이터 예측 결과 시각화
plt.figure(figsize=(10, 5))

# y_train의 X축 데이터는 train_data 범위 내에서 look_back을 제외한 기간
plt.plot(df[look_back : len(train_data)].index, y_train, label='Actual Train Price')  # len(train_data) : 1789 , len(y_train): 1759
plt.plot(df[look_back : len(train_data)].index, train_predict, label='Predicted Train Price')  # len(train_predict) : 1759

# y_test의 X축 데이터는 test_data 범위 내에서 look_back을 제외한 기간
plt.plot(df[len(train_data) + look_back : len(df)].index, y_test, label='Actual Test Price') # len(df) : 2557
plt.plot(df[len(train_data) + look_back : len(df)].index, test_predict, label='Predicted Test Price')

# 2021년 5월 13일에 빨간색 세로축을 추가합니다.
target_date = datetime.datetime(2021, 5, 13)
plt.axvline(x=target_date, color='red', linestyle='--')

# 2022년 2월 24일에 빨간색 세로축을 추가합니다.
tar_date = datetime.datetime(2022, 2, 24)
plt.axvline(x=tar_date, color='red', linestyle='--')
plt.gca().yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{round(int(x)/1400,1):,}$')) # y축 달러로 설정
plt.grid(True, axis='y') # 그리드 설정

# 범례를 표시하여 각 선이 무엇을 의미하는지 보여줍니다.
plt.legend()
plt.title("GRU prediction model")
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.show()

# 모델 정확도 판별
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error

mae_train= mean_absolute_error(y_train, train_predict)
mae_test= mean_absolute_error(y_test, test_predict)

mse_train= mean_squared_error(y_train, train_predict)
mse_test= mean_squared_error(y_test, test_predict)

rmse_train = np.sqrt(mse_train)
rmse_test = np.sqrt(mse_test)

train_r2_score = r2_score(y_train, train_predict)
test_r2_score = r2_score(y_test, test_predict)

print(f"mae_train Score: {mae_train:.3f}")
print(f"mae_test Score: {mae_test:.3f}")

print(f"mse_train Score: {mse_train:.3f}")
print(f"mse_test Score: {mse_test:.3f}")

print(f"rmse_train Score: {rmse_train:.3f}")
print(f"rmse_testScore: {rmse_test:.3f}")

print(f"Train R2 Score: {train_r2_score:.3f}")
print(f"Test R2 Score: {test_r2_score:.3f}")

# Train R2 Score: 0.997
# Test R2 Score: 0.990

"""## 뉴스 크롤링후 긍정인 말 이있으면 1, 부정인말이있으면 0 으로 라벨링

## 크롤링
## https://wikidocs.net/85739
## https://www.inflearn.com/course/%ED%8C%8C%EC%9D%B4%EC%8D%AC-%ED%81%AC%EB%A1%A4%EB%A7%81-%EA%B8%B0%EC%B4%88/dashboard
"""

pip install pygooglenews



